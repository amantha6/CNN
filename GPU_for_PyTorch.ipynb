{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZrW9QtFFjFmx",
        "outputId": "2fffa9dd-2346-4cf6-cc8d-29ccae50f8e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "print(torch.cuda.get_device_name(0))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU device will have an id\n",
        "torch.cuda.current_device()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYRIMXK6jPLM",
        "outputId": "969f7bcb-7257-4b63-8374-06adfd08c41d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#check how much memory is allocated on the GPU\n",
        "#Pytorch will take more memory from the gpu\n",
        "#This returns the current memory usage by the tensors\n",
        "torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PV7gtLIZjs6n",
        "outputId": "8a47d2c4-3702-4354-d2af-03d74b3e9821"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Current gpu memory managed\n",
        "torch.cuda.memory_cached()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8V0gZ-o-j6pX",
        "outputId": "af6481a9-ce47-4c20-8ad2-babb0793554e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-87c1def07a81>:2: FutureWarning: `torch.cuda.memory_cached` has been renamed to `torch.cuda.memory_reserved`\n",
            "  torch.cuda.memory_cached()\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#For a cpu we would define torch tensors\n",
        "a=torch.FloatTensor([1.0,2.0])"
      ],
      "metadata": {
        "id": "WEr34HqIkHLw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyqtnxbSkOhr",
        "outputId": "6f61ed5c-76d9-43ed-a3fb-6ab0239733f0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1., 2.])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7QlwcKwkPQb",
        "outputId": "df488800-803f-4016-d065-693ecf7a900e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 1 is to specify that we are using the gpu when we are creating the tensorts\n",
        "a=torch.FloatTensor([1.0,2.0]).cuda()"
      ],
      "metadata": {
        "id": "qLqEm5t9kQoQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a.device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--Bin9-dkY1Z",
        "outputId": "924d1d1e-9e15-495b-d51d-c050f00ee2e4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Call .cuda for creating the tensors on the GPU\n",
        "#Check how much memory is allocated\n",
        "torch.cuda.memory_allocated()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBaUajXbkaPt",
        "outputId": "0e2e8ab4-c790-4e0f-c966-ce35ff5a2bd8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "2KaL4wprkjDL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, in_features=4, h1=8, h2=9, out_features=3):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(in_features,h1)    # input layer\n",
        "        self.fc2 = nn.Linear(h1, h2)            # hidden layer\n",
        "        self.out = nn.Linear(h2, out_features)  # output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.out(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "DeNIu7pBk9OF"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(32)\n",
        "model = Model()"
      ],
      "metadata": {
        "id": "LyAguNPEk-xh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From the discussions here: discuss.pytorch.org/t/how-to-check-if-model-is-on-cuda\n",
        "next(model.parameters()).is_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lewe1WprlAGE",
        "outputId": "f3333da5-a334-4de9-8e97-9f3d617b89c9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpumodel = model.cuda()"
      ],
      "metadata": {
        "id": "RnbL77uKlBg6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(gpumodel.parameters()).is_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou99suxglCxb",
        "outputId": "75544a27-877f-4276-b5ad-1127a6e24e4d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the Iris dataset from the URL\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Inspect the DataFrame to confirm column names\n",
        "print(df.head())\n",
        "print(df.columns)\n",
        "\n",
        "# Use 'species' as the target column\n",
        "X = df.drop('species', axis=1).values\n",
        "y = df['species'].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=33)\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Test data shape:\", X_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Do8D8SPYlEDO",
        "outputId": "4c35b911-8303-454f-80dd-ad574131c8fa"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "Index(['sepal_length', 'sepal_width', 'petal_length', 'petal_width',\n",
            "       'species'],\n",
            "      dtype='object')\n",
            "Training data shape: (120, 4)\n",
            "Test data shape: (30, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "\n",
        "# Load the Iris dataset from the URL\n",
        "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv\"\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Features and target\n",
        "X = df.drop('species', axis=1).values\n",
        "y = df['species'].values\n",
        "\n",
        "# Encode the species labels as integers\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=33)\n",
        "\n",
        "# Convert the features to PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train).cuda()\n",
        "X_test_tensor = torch.FloatTensor(X_test).cuda()\n",
        "\n",
        "# Convert the labels to PyTorch tensors (encoded as integers)\n",
        "y_train_tensor = torch.LongTensor(y_train).cuda()\n",
        "y_test_tensor = torch.LongTensor(y_test).cuda()\n",
        "\n",
        "# Check shapes of tensors\n",
        "print(f\"X_train_tensor: {X_train_tensor.shape}\")\n",
        "print(f\"y_train_tensor: {y_train_tensor.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK3UcnYylFLc",
        "outputId": "87dbc2da-507c-4b47-9865-9a467002507d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_tensor: torch.Size([120, 4])\n",
            "y_train_tensor: torch.Size([120])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = DataLoader(X_train, batch_size=60, shuffle=True)\n",
        "testloader = DataLoader(X_test, batch_size=60, shuffle=False)"
      ],
      "metadata": {
        "id": "yF-3AD2BlfPf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ],
      "metadata": {
        "id": "sJCPYt1Zls8p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import time\n",
        "\n",
        "# Ensure that X_train and y_train are PyTorch tensors\n",
        "X_train_tensor = torch.FloatTensor(X_train).cuda()\n",
        "y_train_tensor = torch.LongTensor(y_train).cuda()\n",
        "\n",
        "# Training loop\n",
        "epochs = 100\n",
        "losses = []\n",
        "start = time.time()\n",
        "\n",
        "for i in range(epochs):\n",
        "    i += 1\n",
        "    y_pred = gpumodel.forward(X_train_tensor)  # Use the tensor instead of numpy array\n",
        "    loss = criterion(y_pred, y_train_tensor)  # Use tensor for the target labels as well\n",
        "    losses.append(loss)\n",
        "\n",
        "    # a neat trick to save screen space:\n",
        "    if i % 10 == 1:\n",
        "        print(f'epoch: {i:2}  loss: {loss.item():10.8f}')\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f'TOTAL TRAINING TIME: {time.time()-start}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ij1o-u97luic",
        "outputId": "54a57337-f712-4697-ef06-2e4d37141977"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:  1  loss: 1.15074503\n",
            "epoch: 11  loss: 0.93714464\n",
            "epoch: 21  loss: 0.77962422\n",
            "epoch: 31  loss: 0.60785323\n",
            "epoch: 41  loss: 0.39894524\n",
            "epoch: 51  loss: 0.25249201\n",
            "epoch: 61  loss: 0.14927687\n",
            "epoch: 71  loss: 0.10029557\n",
            "epoch: 81  loss: 0.08100693\n",
            "epoch: 91  loss: 0.07216036\n",
            "TOTAL TRAINING TIME: 0.8279578685760498\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHquUhpPlvta"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}